{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrNigZOrwDvTym8bVgbJm7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/plerzundidev/pyspark-ejemplos/blob/main/PySpark_Create_an_Empty_DataFrame_And_RDD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Iniciamos librerias esenciales para su funcionamiento"
      ],
      "metadata": {
        "id": "10p-jloxH0lR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Levantamos google drive para ejecutar el instalador\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6tWkBmYiH_35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daddb71e-d1f8-4a47-8db6-71db203c2e6f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ahora iniciamos pyspark\n",
        "exec(open('/content/drive/MyDrive/BigDataSw/spark_colab_installer_new.py').read())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SO87cBYJRUb",
        "outputId": "e7201d52-2436-4c93-981e-713e9393073f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Servicios Activos:\n",
            "2384 NodeManager\n",
            "2161 NameNode\n",
            "2229 DataNode\n",
            "2549 Jps\n",
            "2311 ResourceManager\n",
            "2492 JobHistoryServer\n",
            "\n",
            "Apache Spark installed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este artículo, voy a explicar cómo crear un PySpark DataFrame/RDD vacío manualmente con o sin esquema (nombres de columnas) de diferentes maneras. A continuación he explicado uno de los muchos escenarios en los que necesitamos crear un DataFrame vacío.\n",
        "\n",
        "Mientras trabajamos con ficheros, a veces puede que no recibamos un fichero para procesar, sin embargo, necesitamos crear un DataFrame manualmente con el mismo esquema que esperamos. Si no lo creamos con el mismo esquema, nuestras operaciones/transformaciones (como las uniones) en el DataFrame fallan ya que nos referimos a las columnas que pueden no estar presentes.\n",
        "\n",
        "Para manejar situaciones similares a estas, siempre necesitamos crear un DataFrame con el mismo esquema, lo que significa los mismos nombres de columnas y tipos de datos sin importar si el archivo existe o está vacío."
      ],
      "metadata": {
        "id": "qwWp6A0jSIZ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Crear un RDD vacío en PySpark\n",
        "\n",
        "Crea un RDD vacío utilizando emptyRDD() de SparkContext por ejemplo spark.sparkContext.emptyRDD()."
      ],
      "metadata": {
        "id": "9Yy5eCjJSSUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# esencial para que el contenedor reconozca la instalacion de pyspark\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()"
      ],
      "metadata": {
        "id": "sFw42smwJhFw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creates Empty RDD\n",
        "emptyRDD = spark.sparkContext.emptyRDD()\n",
        "print(emptyRDD)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHTS_AR8SwKX",
        "outputId": "c007ce74-b445-41bf-a2bb-0fe0eb63e9a5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EmptyRDD[0] at emptyRDD at NativeMethodAccessorImpl.java:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternativamente también puedes obtener RDD vacíos usando spark.sparkContext.parallelize([]).\n",
        "\n",
        "**Nota**: Si intenta realizar operaciones en un RDD vacío obtendrá ValueError(\"RDD está vacío\")."
      ],
      "metadata": {
        "id": "QypiDidoS64g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creates Empty RDD using parallelize\n",
        "rdd2= spark.sparkContext.parallelize([])\n",
        "print(rdd2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvUakGumSykx",
        "outputId": "3eb2d445-1cc7-4eb0-e186-e328798606bd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ParallelCollectionRDD[1] at readRDDFromFile at PythonRDD.scala:289\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Crear DataFrame vacío con esquema (StructType)\n",
        "\n",
        "Para crear un PySpark DataFrame vacío manualmente con un esquema (nombres de columnas y tipos de datos) primero, Crea un esquema usando StructType y StructField ."
      ],
      "metadata": {
        "id": "1sXO8r4eTMfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Schema\n",
        "from pyspark.sql.types import StructType,StructField, StringType\n",
        "\n",
        "schema = StructType([\n",
        "  StructField('firstname', StringType(), True),\n",
        "  StructField('middlename', StringType(), True),\n",
        "  StructField('lastname', StringType(), True)\n",
        "  ])"
      ],
      "metadata": {
        "id": "NSF-qKbOS-ix"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora utiliza el RDD vacío creado anteriormente y pásalo a createDataFrame() de SparkSession junto con el esquema de nombres de columnas y tipos de datos.\n",
        "\n",
        "Esto produce el siguiente esquema del DataFrame vacío."
      ],
      "metadata": {
        "id": "Xl6pevmrTdaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create empty DataFrame from empty RDD\n",
        "df = spark.createDataFrame(emptyRDD,schema)\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utl4gf3uTY2A",
        "outputId": "adf3a84a-8695-4152-ee68-25b1eb9450e7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- middlename: string (nullable = true)\n",
            " |-- lastname: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Convertir RDD vacío en DataFrame\n",
        "\n",
        "También puede crear un DataFrame vacío convirtiendo un RDD vacío en un DataFrame utilizando toDF()."
      ],
      "metadata": {
        "id": "iMR_xIFfT-PB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert empty RDD to Dataframe\n",
        "df1 = emptyRDD.toDF(schema)\n",
        "df1.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SGb_9VfThHy",
        "outputId": "837d2812-4497-4e2b-ef29-070ecd27632d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- middlename: string (nullable = true)\n",
            " |-- lastname: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Crear DataFrame vacío con esquema.\n",
        "\n",
        "Hasta ahora he cubierto la creación de un DataFrame vacío desde RDD, pero aquí lo crearemos manualmente con esquema y sin RDD."
      ],
      "metadata": {
        "id": "utRMhWKNUwfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create empty DataFrame directly.\n",
        "df2 = spark.createDataFrame([], schema)\n",
        "df2.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_u67Z6vwUIH3",
        "outputId": "e94be35e-0658-4eb7-86db-058b33bc9274"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- middlename: string (nullable = true)\n",
            " |-- lastname: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Crear DataFrame vacío sin esquema (sin columnas)\n",
        "Para crear un DataFrame vacío sin esquema (sin columnas) simplemente crea un esquema vacío y úsalo mientras creas el DataFrame de PySpark."
      ],
      "metadata": {
        "id": "RSkJu7brVPrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create empty DatFrame with no schema (no columns)\n",
        "df3 = spark.createDataFrame([], StructType([]))\n",
        "df3.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_324UpA8U59r",
        "outputId": "5fc5d38b-9116-4c70-9079-019dffa8a714"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kVPHEA5BVY73"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}