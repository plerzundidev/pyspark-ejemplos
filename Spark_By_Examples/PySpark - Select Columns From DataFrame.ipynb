{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17b9156a-6844-46f2-b94b-6a33340793f9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "En PySpark, la función select() se utiliza para seleccionar una sola columna, varias, columna por índice, todas las columnas de la lista y las columnas anidadas de un DataFrame, PySpark select() es una función de transformación por lo tanto devuelve un nuevo DataFrame con las columnas seleccionadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eeed3579-729d-412f-bdd1-063aeee32a6c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------+-----+\n|firstname|lastname|country|state|\n+---------+--------+-------+-----+\n|James    |Smith   |USA    |CA   |\n|Michael  |Rose    |USA    |NY   |\n|Robert   |Williams|USA    |CA   |\n|Maria    |Jones   |USA    |FL   |\n+---------+--------+-------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "data = [(\"James\",\"Smith\",\"USA\",\"CA\"),\n",
    "    (\"Michael\",\"Rose\",\"USA\",\"NY\"),\n",
    "    (\"Robert\",\"Williams\",\"USA\",\"CA\"),\n",
    "    (\"Maria\",\"Jones\",\"USA\",\"FL\")\n",
    "  ]\n",
    "columns = [\"firstname\",\"lastname\",\"country\",\"state\"]\n",
    "df = spark.createDataFrame(data = data, schema = columns)\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0f74f06-6137-4e20-970a-1d596973fd9e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#1. Seleccionar Columnas Individuales y Múltiples desde PySpark\n",
    "Puedes seleccionar una o múltiples columnas del DataFrame pasando los nombres de las columnas que quieres seleccionar a la función select(). Como el DataFrame es inmutable, se crea un nuevo DataFrame con las columnas seleccionadas. La función show() se utiliza para mostrar el contenido del DataFrame.\n",
    "\n",
    "A continuación se muestran las formas de seleccionar una, varias o todas las columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55e00af3-c433-493d-908d-5e334fe89f15",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n|firstname|lastname|\n+---------+--------+\n|    James|   Smith|\n|  Michael|    Rose|\n|   Robert|Williams|\n|    Maria|   Jones|\n+---------+--------+\n\n+---------+--------+\n|firstname|lastname|\n+---------+--------+\n|    James|   Smith|\n|  Michael|    Rose|\n|   Robert|Williams|\n|    Maria|   Jones|\n+---------+--------+\n\n+---------+--------+\n|firstname|lastname|\n+---------+--------+\n|    James|   Smith|\n|  Michael|    Rose|\n|   Robert|Williams|\n|    Maria|   Jones|\n+---------+--------+\n\n+---------+--------+\n|firstname|lastname|\n+---------+--------+\n|    James|   Smith|\n|  Michael|    Rose|\n|   Robert|Williams|\n|    Maria|   Jones|\n+---------+--------+\n\n+---------+--------+\n|firstname|lastname|\n+---------+--------+\n|    James|   Smith|\n|  Michael|    Rose|\n|   Robert|Williams|\n|    Maria|   Jones|\n+---------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "df.select(\"firstname\",\"lastname\").show()\n",
    "df.select(df.firstname,df.lastname).show()\n",
    "df.select(df[\"firstname\"],df[\"lastname\"]).show()\n",
    "\n",
    "#By using col() function\n",
    "from pyspark.sql.functions import col\n",
    "df.select(col(\"firstname\"),col(\"lastname\")).show()\n",
    "\n",
    "#Select columns by regular expression\n",
    "df.select(df.colRegex(\"`^.*name*`\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "170b9b86-d45e-4df3-9b74-806df62062dd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 2. Seleccionar todas las columnas de una lista\n",
    "A veces puede ser necesario seleccionar todas las columnas del DataFrame de una lista de Python. En el siguiente ejemplo, tenemos todas las columnas en el objeto de lista columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97ec776d-6539-4d0b-b48a-2ea4136f63d0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------+-----+\n|firstname|lastname|country|state|\n+---------+--------+-------+-----+\n|    James|   Smith|    USA|   CA|\n|  Michael|    Rose|    USA|   NY|\n|   Robert|Williams|    USA|   CA|\n|    Maria|   Jones|    USA|   FL|\n+---------+--------+-------+-----+\n\n+---------+--------+-------+-----+\n|firstname|lastname|country|state|\n+---------+--------+-------+-----+\n|    James|   Smith|    USA|   CA|\n|  Michael|    Rose|    USA|   NY|\n|   Robert|Williams|    USA|   CA|\n|    Maria|   Jones|    USA|   FL|\n+---------+--------+-------+-----+\n\n+---------+--------+-------+-----+\n|firstname|lastname|country|state|\n+---------+--------+-------+-----+\n|    James|   Smith|    USA|   CA|\n|  Michael|    Rose|    USA|   NY|\n|   Robert|Williams|    USA|   CA|\n|    Maria|   Jones|    USA|   FL|\n+---------+--------+-------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# Select All columns from List\n",
    "df.select(*columns).show()\n",
    "\n",
    "# Select All columns\n",
    "df.select([col for col in df.columns]).show()\n",
    "df.select(\"*\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f06151c-d8b4-44ca-b8aa-89dc14860aa9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#3. Seleccionar columnas por índice\n",
    "Usando las características de una lista de python, puede seleccionar las columnas por índice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9636e21b-3d56-4e1a-b19f-549ae2a7625a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------+\n|firstname|lastname|country|\n+---------+--------+-------+\n|    James|   Smith|    USA|\n|  Michael|    Rose|    USA|\n|   Robert|Williams|    USA|\n+---------+--------+-------+\nonly showing top 3 rows\n\n+-------+-----+\n|country|state|\n+-------+-----+\n|    USA|   CA|\n|    USA|   NY|\n|    USA|   CA|\n+-------+-----+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "#Selects first 3 columns and top 3 rows\n",
    "df.select(df.columns[:3]).show(3)\n",
    "\n",
    "#Selects columns 2 to 4  and top 3 rows\n",
    "df.select(df.columns[2:4]).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a8e2e26-f4da-401d-ac79-e76467f07fdf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#4. Seleccionar Columnas Struct Anidadas de PySpark\n",
    "Si tienes una columna struct anidada (StructType) en el DataFrame de PySpark, necesitas usar un calificador de columna explícito para poder seleccionar. Si eres nuevo en PySpark y aún no has aprendido StructType, te recomendaría saltarte el resto de la sección o entender primero PySpark StructType antes de continuar.\n",
    "Primero, vamos a crear un nuevo DataFrame con un tipo struct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33ec343f-3e09-451d-9897-c880518a7b50",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- name: struct (nullable = true)\n |    |-- firstname: string (nullable = true)\n |    |-- middlename: string (nullable = true)\n |    |-- lastname: string (nullable = true)\n |-- state: string (nullable = true)\n |-- gender: string (nullable = true)\n\n+----------------------+-----+------+\n|name                  |state|gender|\n+----------------------+-----+------+\n|{James, null, Smith}  |OH   |M     |\n|{Anna, Rose, }        |NY   |F     |\n|{Julia, , Williams}   |OH   |F     |\n|{Maria, Anne, Jones}  |NY   |M     |\n|{Jen, Mary, Brown}    |NY   |M     |\n|{Mike, Mary, Williams}|OH   |M     |\n+----------------------+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "        ((\"James\",None,\"Smith\"),\"OH\",\"M\"),\n",
    "        ((\"Anna\",\"Rose\",\"\"),\"NY\",\"F\"),\n",
    "        ((\"Julia\",\"\",\"Williams\"),\"OH\",\"F\"),\n",
    "        ((\"Maria\",\"Anne\",\"Jones\"),\"NY\",\"M\"),\n",
    "        ((\"Jen\",\"Mary\",\"Brown\"),\"NY\",\"M\"),\n",
    "        ((\"Mike\",\"Mary\",\"Williams\"),\"OH\",\"M\")\n",
    "        ]\n",
    "\n",
    "from pyspark.sql.types import StructType,StructField, StringType        \n",
    "schema = StructType([\n",
    "    StructField('name', StructType([\n",
    "         StructField('firstname', StringType(), True),\n",
    "         StructField('middlename', StringType(), True),\n",
    "         StructField('lastname', StringType(), True)\n",
    "         ])),\n",
    "     StructField('state', StringType(), True),\n",
    "     StructField('gender', StringType(), True)\n",
    "     ])\n",
    "df2 = spark.createDataFrame(data = data, schema = schema)\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False) # shows all columns\n",
    "\n",
    "# El resultado es el siguiente esquema. Si se fija, la columna nombre es de tipo struct y consta de las columnas firstname, middlename, lastname."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "394121ca-e223-4ac6-a395-97289271d6ac",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Ahora, seleccionemos la columna struct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82ccbfed-378f-4c38-a098-2f778be7d189",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n|name                  |\n+----------------------+\n|{James, null, Smith}  |\n|{Anna, Rose, }        |\n|{Julia, , Williams}   |\n|{Maria, Anne, Jones}  |\n|{Jen, Mary, Brown}    |\n|{Mike, Mary, Williams}|\n+----------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df2.select(\"name\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "36d28ca6-d338-40f2-b05c-71943d637623",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Para seleccionar una columna específica de una estructura anidada, debe calificar explícitamente el nombre de la columna de la estructura anidada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8123ec78-24c9-4650-b1f6-497be7918ae4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n|firstname|lastname|\n+---------+--------+\n|James    |Smith   |\n|Anna     |        |\n|Julia    |Williams|\n|Maria    |Jones   |\n|Jen      |Brown   |\n|Mike     |Williams|\n+---------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "df2.select(\"name.firstname\",\"name.lastname\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "521bc6b3-693d-4bea-96d8-91a6e4307c14",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Para obtener todas las columnas de struct column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4265bb8-40a0-4b7d-a046-23a0b0761afa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+\n|firstname|middlename|lastname|\n+---------+----------+--------+\n|James    |null      |Smith   |\n|Anna     |Rose      |        |\n|Julia    |          |Williams|\n|Maria    |Anne      |Jones   |\n|Jen      |Mary      |Brown   |\n|Mike     |Mary      |Williams|\n+---------+----------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "df2.select(\"name.*\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37b87f35-ffb4-4754-9af3-048c85e9bf69",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#5. Conclusión\n",
    "En este artículo, has aprendido select() es una función de transformación del DataFrame y se utiliza para seleccionar columnas individuales, múltiples, seleccionar todas las columnas de la lista, seleccionar por índice, y finalmente seleccionar columnas struct anidadas, también has aprendido como seleccionar elementos anidados del DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27ca1b46-714a-4eff-a20c-8181f9558b3c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "PySpark -  Select Columns From DataFrame",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
